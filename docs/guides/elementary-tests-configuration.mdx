---
title: "Anomaly detection tests configuration"
sidebarTitle: "Tests configuration"
---

The anomaly detection tests configuration is defined in `.yml` files in your dbt project, just like in native dbt tests.

<Snippet file="faq/tests-configuration-priorities.mdx" />

---

## All configuration params

## Configuration by test

## Example configurations


Test specific configurations, configured in the yml for each test (like dbt `severity`, `limit`, etc).

#### Configuration for all anomaly detection tests:

<AccordionGroup>

<Accordion title="timestamp_column">
`timestamp_column`: [column_name]

It is recommended to configure a timestamp column (if there is one).
The best column for this will have an 'updated at' timestamp for each row (date type also works).
Elementary will use this column to filter the table when running monitors.
( `timestamp_column` can be defined for the whole table as well).

If undefined, default is null (no time buckets).

</Accordion>

<Accordion title="time_bucket">
```
time_bucket:
  period: < time period > # supported periods: day, hour, week
  count: < number of periods >
```

This field controls the cadence in which we monitor metrics during the training period (the `days_back` parameter). By
default, the time bucket is daily (period=`day`, count=`1`) - meaning we calculate a metric value per day and use the
resulting values for anomaly calculation (for example, daily volume / row count).

Depending on the nature of your data, it may make sense to modify this parameter. For example, if you wish to have
hourly cadence for a volume anomalies test, it may make sense to set the time bucket to period=`hour` and count=`1`.

_Note_ - you should only decrease the size of the time buckets if this value is expected to be stable during the
period of choosing (for example - if row count tends to be stable on a daily level, but changes dramatically between
different hours, avoid setting an hourly time bucket)

</Accordion>

<Accordion title="anomaly_sensitivity">
`anomaly_sensitivity`: [int]

Threshold for the anomaly sensitivity, the [global default](/guides/add-elementary-tests) is 3. If defined for a test, the test param is used instead of the global one.
A higher number means less sensitivity (less anomalies), and a lower number means more sensitivity (more anomalies).

</Accordion>

<Accordion title="backfill_days">
`backfill_days`: [int]

The minimal amount of buckets for running time buckets monitors. If these buckets were already calculated, Elementary will overwrite them. The reason behind it is to monitor recent backfills of data, if there were any.
This configuration should be changed according to your data delays.

If undefined, default is 2 buckets.

</Accordion>

<Accordion title="where_expression">
`where_expression`: [sql expression]

Filter the tested data using a valid sql expression. Example usage: `where_expression: "user_name = 'test'"`

</Accordion>


</AccordionGroup>


#### Configuration for specific anomaly detection tests:

<AccordionGroup>

<Accordion title="column_anomalies" description="all_column_anomalies, column_anomalies">
`column_anomalies`: [list]

Select which monitors to activate as part of the test. Example usage: `column_anomalies: [null_count, missing_count, average]`

Available monitors:

<Snippet file="column-metrics.mdx" />

</Accordion>

<Accordion title="event_timestamp_column & update_timestamp_column" description="event_freshness_anomalies">
`event_timestamp_column`: [column name]
`update_timestamp_column`: [column name]

This test compliments the freshness_anomalies test and is primarily intended for data that is updated in a continuous / streaming fashion.

The test can work in a couple of modes:

- If only an event_timestamp_column is supplied, the test measures over time the difference between the current timestamp (“now”) and the most recent event timestamp.
- If both an event_timestamp_column and an update_timestamp_column are provided, the test will measure over time the difference between these two columns.

</Accordion>

<Accordion title="exclude_regexp" description="all_column_anomalies">
`exclude_regexp`: [regex]

Param for the `all_columns_anomalies` test only, which enables to exclude a column from the tests based on regular expression match. Example usage: `exlude_regexp: '.*SDC$'`

</Accordion>

<Accordion title="exclude_prefix" description="all_column_anomalies">
`exclude_prefix`: [string]

Param for the `all_columns_anomalies` test only, which enables to exclude a column from the tests based on prefix match. Example usage: `exlude_prefix: 'dbt_'`

</Accordion>

</AccordionGroup>

---

## Table configuration

Elementary tests `timestamp_column` can be configured for a model / source.
This will apply to any test defined on the table that has no `timestamp_column` param.

<Accordion title="timestamp_column">
`timestamp_column`: [column_name]

It is recommended to configure a timestamp column (if there is one).
The best column for this will have an 'updated at' timestamp for each row (date type also works).
Elementary will use this column to filter the table when running monitors.

If undefined, default is null (no time buckets).

**Example configuration:**

<CodeGroup>

```yml properties.yml
version: 2

models:
  - name: <model_name>
    config:
      elementary:
        timestamp_column: < model timestamp column >
    tests: < here you will add elementary monitors as tests >

  - name: <your model with no timestamp>
    ## if no timestamp is configured, elementary will monitor without time filtering
    tests: <here you will add elementary monitors as tests>
```

```yml Example
version: 2

models:
  - name: login_events
    config:
      elementary:
        timestamp_column: updated_at
    tests:
      - elementary.table_anomalies:
          tags: ["elementary"]
      - elementary.all_columns_anomalies:
          tags: ["elementary"]

  - name: users
    ## if no timestamp is configured, elementary will monitor without time filtering
    tests:
      - elementary.table_anomalies:
          tags: ["elementary"]
```

```yml sources_properties.yml
sources:
  - name: < some name >
    database: < datatbase >
    schema: < schema >
    tables:
      - name: < table_name >
        ## sources don't have config, so elementary config is placed under 'meta'
        meta:
          elementary:
            timestamp_column: < source timestamp column >
        tests: <here you will add elementary monitors as tests>
```

```yml Example
sources:
  - name: "my_non_dbt_table"
    database: "raw_events"
    schema: "product"
    tables:
      - name: "raw_product_login_events"
        ## sources don't have config, so elementary config is placed under 'meta'
        meta:
          elementary:
            timestamp_column: "loaded_at"
        tests:
          - elementary.table_anomalies
          - elementary.all_columns_anomalies:
              column_anomalies:
                - null_count
                - missing_count
                - zero_count
        columns:
          - name: user_id
            tests:
              - elementary.column_anomalies
```

</CodeGroup>

</Accordion>

---

## Data monitoring global vars

Elementary has several global vars used for tests configurations.
You can change their defaults by adding them with a new value in your `dbt_project.yml` under the vars key.

<AccordionGroup>

<Accordion title="days_back">
`days_back`: [int]

The maximum timeframe for running [time buckets](/guides/data-anomaly-detection#tests-and-monitors-types) monitors, as well as to calculate a baseline for anomaly detection.
This limit is applied in three cases: - On the first run of elementary or on full refresh (first run for all tables). - For each new table that is added to the monitoring (first run for table). - On each new metric that is added to the configuration (first run of new metric). - If there was a gap bigger than this limit since the last run.
If undefined, _default is 14 days back_.

</Accordion>

<Accordion title="backfill_days">
`backfill_days`: [int]

The minimal amount of buckets for running time buckets monitors. If these buckets were already calculated, Elementary will overwrite them. The reason behind it is to monitor recent backfills of data, if there were any. This configuration should be changed according to your data delays.
If undefined, _default is 2 buckets_.

</Accordion>

<Accordion title="anomaly_sensitivity">
`anomaly_sensitivity`: [int]

This threshold determines the sensitivity level for anomaly detection. Elementary uses [statistical analysis](/guides/data-anomaly-detection#anomaly-detection) to grade deviations of recent metrics from historical metrics. Increasing this threshold makes the detection less sensitive for anomalies, and reducing makes it more sensitive (smaller deviations will be flagged as anomalies).
If undefined, _default threshold is 3_.

</Accordion>

</AccordionGroup>

```yml dbt_project.yml
# optional #
# Global vars for data monitoring#
vars:
  days_back: 14 # maximum timeframe for collecting metrics and analyzing anomalies
  anomaly_sensitivity: 3 # sensitivity of anomaly detection
  backfill_days: 2 # days to backfill on each run, adjust to your data delays
```
